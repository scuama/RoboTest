#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–å®éªŒè¿è¡Œè„šæœ¬ - ç®€åŒ–ç‰ˆæœ¬
ç”¨äºé‡æ–°è¿è¡Œå·²ä¿å­˜çš„BDDLé…ç½®ï¼Œä¸éœ€è¦åŠ¨æ€åœºæ™¯ä¿®æ”¹
"""

import sys
import os

# âš ï¸ å¿…é¡»åœ¨ä»»ä½•å¯¼å…¥ä¹‹å‰è®¾ç½®è­¦å‘ŠæŠ‘åˆ¶
import warnings
warnings.filterwarnings("ignore")
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# è®¾ç½®ç¯å¢ƒå˜é‡æŠ‘åˆ¶è­¦å‘Š
os.environ["PYTHONWARNINGS"] = "ignore"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # æŠ‘åˆ¶TensorFlowæ—¥å¿—

# æŠ‘åˆ¶JAX/Flaxçš„DeprecationWarning
import logging
logging.captureWarnings(True)
logging.getLogger('py.warnings').setLevel(logging.ERROR)

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["MUJOCO_GL"] = "egl"
os.environ["PYOPENGL_PLATFORM"] = "egl"

# ç»§ç»­æŠ‘åˆ¶robosuiteæ—¥å¿—
logging.getLogger("robosuite_logs").setLevel(logging.ERROR)
logging.getLogger("robosuite").setLevel(logging.ERROR)

import yaml
import json
import numpy as np
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict
import math
import cv2
import time

# æ·»åŠ è·¯å¾„ï¼ˆéœ€è¦ç”¨æˆ·æ ¹æ®è‡ªå·±çš„ç¯å¢ƒé…ç½®ï¼‰
# sys.path.insert(0, '/path/to/LIBERO')
# sys.path.insert(0, '/path/to/openpi/src')

# è·å–å½“å‰è„šæœ¬ç›®å½•
SCRIPT_DIR = Path(__file__).parent.absolute()
sys.path.insert(0, str(SCRIPT_DIR))

# å¯¼å…¥OpenPI
from openpi.training import config as _config
from openpi.policies import policy_config


def _quat2axisangle(quat):
    """å°†å››å…ƒæ•°è½¬æ¢ä¸ºè½´è§’è¡¨ç¤º"""
    w, x, y, z = quat[0], quat[1], quat[2], quat[3]
    w = np.clip(w, -1.0, 1.0)
    den = np.sqrt(1.0 - w * w)
    if math.isclose(den, 0.0, abs_tol=1e-6):
        return np.zeros(3)
    return (np.array([x, y, z]) * 2.0 * math.acos(w)) / den


def extract_robot_state_from_obs(obs):
    """ä»LIBEROç¯å¢ƒè§‚å¯Ÿä¸­æå–8ç»´æœºå™¨äººçŠ¶æ€"""
    eef_pos = obs["robot0_eef_pos"]
    eef_quat = obs["robot0_eef_quat"]
    gripper_qpos = obs["robot0_gripper_qpos"]
    
    eef_axisangle = _quat2axisangle(eef_quat)
    gripper_pos = np.mean(gripper_qpos)
    
    robot_state = np.concatenate([
        eef_pos,           # 3ç»´ï¼šæœ«ç«¯ä½ç½®
        eef_axisangle,     # 3ç»´ï¼šæ—‹è½¬è½´è§’
        gripper_qpos[:1],  # 1ç»´ï¼šå¤¹çˆªä½ç½®
        [gripper_pos]      # 1ç»´ï¼šå¤¹çˆªå¹³å‡ä½ç½®
    ])
    
    return robot_state.astype(np.float32)


def process_camera_image(obs, camera_key):
    """å¤„ç†ç›¸æœºå›¾åƒ"""
    image = obs[camera_key]
    
    # æ—‹è½¬180åº¦ï¼ˆä¸pi05_libero_visual_inference_fixed.pyä¿æŒä¸€è‡´ï¼‰
    image = image[::-1, ::-1]
    
    # ç¡®ä¿æ ¼å¼ä¸ºuint8 (H,W,C)
    if image.dtype != np.uint8:
        if image.max() <= 1.0:
            image = (image * 255).astype(np.uint8)
        else:
            image = image.astype(np.uint8)
    return image


def load_pi05_model(checkpoint_dir: str):
    """åŠ è½½Pi0.5æ¨¡å‹"""
    try:
        config_name = os.path.basename(checkpoint_dir)
        config = _config.get_config(config_name)
        model = policy_config.create_trained_policy(config, checkpoint_dir)
        print("âœ… Pi0.5æ¨¡å‹åŠ è½½å®Œæˆ")
        return model, config
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def find_task_id_by_name(task_name: str, suite: str = "libero_90") -> int:
    """é€šè¿‡ä»»åŠ¡åæŸ¥æ‰¾task_id"""
    from libero.libero import benchmark
    
    benchmark_dict = benchmark.get_benchmark_dict()
    task_suite = benchmark_dict[suite]()
    
    for i, task in enumerate(task_suite.tasks):
        if task.name == task_name:
            return i
    
    raise ValueError(f"æ‰¾ä¸åˆ°ä»»åŠ¡: {task_name}")


def run_multi_stage_group(env, config: Dict, group_config: Dict, group_name: str,
                          output_dir: Path, model, model_config, task_suite, task_id: int) -> Dict:
    """è¿è¡Œå¤šé˜¶æ®µå®éªŒç»„"""
    from libero.libero.envs import OffScreenRenderEnv
    
    group_dir = output_dir / group_name
    group_dir.mkdir(parents=True, exist_ok=True)
    
    episodes_per_group = config['execution']['episodes_per_group']
    max_steps = config['execution']['max_steps_per_episode']
    
    results = []
    stage_configs = group_config['stages']
    
    for episode_idx in range(episodes_per_group):
        print(f"\n{'='*60}")
        print(f"ğŸ“ Episode {episode_idx + 1}/{episodes_per_group}")
        print(f"{'='*60}")
        
        # åˆ›å»ºepisodeç›®å½•
        episode_dir = group_dir / f"episode_{episode_idx}"
        episode_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºåˆ†è§†è§’çš„imagesç›®å½•
        frontview_dir = episode_dir / "images" / "frontview"
        wrist_dir = episode_dir / "images" / "wrist"
        frontview_dir.mkdir(parents=True, exist_ok=True)
        wrist_dir.mkdir(parents=True, exist_ok=True)
        
        step_offset = 0  # æ­¥éª¤åç§»é‡ï¼ˆè·¨stageè¿ç»­ï¼‰
        stage_info = []  # è®°å½•æ¯ä¸ªstageçš„æ­¥æ•°èŒƒå›´
        episode_success = True
        
        # é€ä¸ªè¿è¡Œstage
        for stage_idx, stage_config in enumerate(stage_configs, 1):
            stage_name = stage_config.get('stage_name', f'stage{stage_idx}')
            bddl_file = stage_config['bddl_file']
            instruction = stage_config['instruction']
            
            print(f"\nğŸ¬ Stage {stage_idx}/{len(stage_configs)}: {stage_name}")
            print(f"   BDDL: {bddl_file}")
            print(f"   æŒ‡ä»¤: {instruction}")
            
            # åˆ‡æ¢BDDLæ–‡ä»¶ï¼Œåˆ›å»ºæ–°ç¯å¢ƒ
            if not bddl_file.startswith('/'):
                # å°è¯•ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾
                bddl_path = SCRIPT_DIR.parent / bddl_file
                if not bddl_path.exists():
                    bddl_path = Path(bddl_file)
            else:
                bddl_path = Path(bddl_file)
            
            env_args = {
                "bddl_file_name": str(bddl_path),
                "camera_heights": 224,
                "camera_widths": 224,
                "has_renderer": False,
                "has_offscreen_renderer": True,
                "use_camera_obs": True,
                "camera_names": ["frontview", "robot0_eye_in_hand"],
                "control_freq": 20,
            }
            
            try:
                env = OffScreenRenderEnv(**env_args)
                env.seed(config['execution']['seed_start'] + episode_idx)
            except Exception as e:
                # æ•è·ç‰©ä½“æ”¾ç½®å¤±è´¥ç­‰å¼‚å¸¸
                error_msg = str(e)
                if "Cannot place all objects" in error_msg:
                    print(f"âš ï¸  Stage {stage_idx} ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼šç‰©ä½“æ”¾ç½®ç©ºé—´ä¸è¶³")
                    print(f"   BDDL: {bddl_file}")
                    episode_success = False
                    # è¿”å›å¤±è´¥ç»“æœ
                    summary = {
                        "success_count": 0,
                        "total_episodes": episodes_per_group,
                        "success_rate": 0.0,
                        "error": "placement_failed_in_stage",
                        "failed_stage": stage_idx
                    }
                    return env, summary
                else:
                    raise
            
            # é‡ç½®ç¯å¢ƒ
            obs = env.reset()
            env.sim.data.qvel[:] = 0
            env.sim.forward()
            for _ in range(5):
                env.sim.step()
            
            # é‡ç½®æ¨¡å‹çŠ¶æ€
            model.reset()
            
            # åŠ¨ä½œåºåˆ—ç¼“å­˜
            action_cache = []
            action_cache_step = 0
            inference_count = 0
            stage_step_count = 0
            stage_success = False
            
            for step in range(max_steps):
                # æå–çŠ¶æ€å’Œå›¾åƒ
                robot_state = extract_robot_state_from_obs(obs)
                base_image = process_camera_image(obs, "frontview_image")
                wrist_image = process_camera_image(obs, "robot0_eye_in_hand_image")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°çš„æ¨ç†
                if len(action_cache) == 0 or action_cache_step >= len(action_cache):
                    inference_count += 1
                    
                    model_input = {
                        "observation/state": robot_state,
                        "observation/image": base_image,
                        "observation/wrist_image": wrist_image,
                        "prompt": instruction
                    }
                    
                    with torch.no_grad():
                        result = model.infer(model_input)
                        action_sequence = result["actions"]
                    
                    action_cache = action_sequence
                    action_cache_step = 0
                    
                    if step % 50 == 0 or inference_count <= 3:
                        print(f"  [æ¨ç†{inference_count}] æ­¥éª¤{step+1}: ç”Ÿæˆ{len(action_cache)}æ­¥åŠ¨ä½œåºåˆ—")
                
                # ä»ç¼“å­˜ä¸­è·å–åŠ¨ä½œ
                action = action_cache[action_cache_step]
                action_cache_step += 1
                
                if isinstance(action, torch.Tensor):
                    action = action.cpu().numpy().squeeze()
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs, reward, done, info = env.step(action)
                stage_step_count += 1
                
                # âœ… ä½¿ç”¨å…¨å±€æ­¥éª¤ç¼–å·ï¼ˆstep_offset + stage_step_countï¼‰
                global_step = step_offset + stage_step_count
                
                # ä¿å­˜å›¾åƒ
                try:
                    front_bgr = cv2.cvtColor(base_image, cv2.COLOR_RGB2BGR)
                    wrist_bgr = cv2.cvtColor(wrist_image, cv2.COLOR_RGB2BGR)
                    
                    frontview_filename = frontview_dir / f"step_{global_step:05d}.png"
                    wrist_filename = wrist_dir / f"step_{global_step:05d}.png"
                    
                    cv2.imwrite(str(frontview_filename), front_bgr)
                    cv2.imwrite(str(wrist_filename), wrist_bgr)
                except Exception as e:
                    print(f"    âš ï¸  å›¾åƒä¿å­˜é”™è¯¯: {e}")
                
                if step % 50 == 0:
                    print(f"    Step {global_step} (stageå†…ç¬¬{stage_step_count}æ­¥)")
                
                if done:
                    stage_success = True
                    print(f"    âœ“ Stage {stage_idx} å®Œæˆäºæ­¥éª¤ {global_step}")
                    break
            
            # è®°å½•stageä¿¡æ¯
            stage_info.append({
                'stage_name': stage_name,
                'stage_index': stage_idx,
                'step_range': [step_offset + 1, step_offset + stage_step_count],
                'success': stage_success,
                'inference_count': inference_count
            })
            
            # æ›´æ–°step_offset
            step_offset += stage_step_count
            
            if not stage_success:
                print(f"    âœ— Stage {stage_idx} æœªå®Œæˆï¼Œç»ˆæ­¢episode")
                episode_success = False
                break
            
            # å…³é—­å½“å‰stageçš„ç¯å¢ƒ
            env.close()
        
        # ä¿å­˜stageä¿¡æ¯
        stage_info_file = episode_dir / "stage_info.json"
        with open(stage_info_file, 'w') as f:
            json.dump({
                'episode_index': episode_idx,
                'total_steps': step_offset,
                'stages': stage_info,
                'overall_success': episode_success
            }, f, indent=2)
        
        results.append({
            'episode': episode_idx,
            'success': episode_success,
            'total_steps': step_offset,
            'stages': stage_info
        })
        
        print(f"\nğŸ“Š Episode {episode_idx} æ€»ç»“:")
        print(f"   æ€»æ­¥æ•°: {step_offset}")
        print(f"   æˆåŠŸ: {'âœ“' if episode_success else 'âœ—'}")
    
    # ç”Ÿæˆç»„æ€»ç»“
    success_count = sum(1 for r in results if r['success'])
    summary = {
        'group_name': group_name,
        'episodes': episodes_per_group,
        'success_count': success_count,
        'success_rate': success_count / episodes_per_group if episodes_per_group > 0 else 0,
        'results': results
    }
    
    with open(group_dir / "summary.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\n{'='*60}")
    print(f"âœ… å¤šé˜¶æ®µç»„ {group_name} å®Œæˆ")
    print(f"   æˆåŠŸç‡: {summary['success_rate']*100:.1f}% ({success_count}/{episodes_per_group})")
    print(f"{'='*60}\n")
    
    return env, summary


def run_group_with_cache(env, config: Dict, group_config: Dict, group_name: str, 
                         output_dir: Path, model, model_config, task_suite, task_id: int) -> Dict:
    """è¿è¡Œå•ä¸ªå®éªŒç»„ - å¸¦åŠ¨ä½œåºåˆ—ç¼“å­˜ + å¤šé˜¶æ®µæ”¯æŒ"""
    
    # âœ… æ£€æµ‹æ˜¯å¦ä¸ºå¤šé˜¶æ®µå®éªŒ
    if 'stages' in group_config:
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ è¿è¡Œå¤šé˜¶æ®µå®éªŒç»„: {group_name}")
        print(f"   æè¿°: {group_config['description']}")
        print(f"   é˜¶æ®µæ•°: {len(group_config['stages'])}")
        print(f"{'='*60}\n")
        return run_multi_stage_group(env, config, group_config, group_name,
                                     output_dir, model, model_config, task_suite, task_id)
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ è¿è¡Œå®éªŒç»„: {group_name}")
    print(f"   æè¿°: {group_config['description']}")
    print(f"   æŒ‡ä»¤: {group_config['instruction']}")
    print(f"   é®æŒ¡: {'æ˜¯' if group_config['use_obstruction'] else 'å¦'}")
    
    # âœ… æ”¯æŒç»„çº§åˆ«çš„BDDLæ–‡ä»¶åˆ‡æ¢
    if 'bddl_file' in group_config:
        group_bddl_path = group_config['bddl_file']
        if not group_bddl_path.startswith('/'):
            group_bddl_path = SCRIPT_DIR.parent / group_bddl_path
            if not group_bddl_path.exists():
                group_bddl_path = Path(group_bddl_path)
        else:
            group_bddl_path = Path(group_bddl_path)
        
        print(f"   BDDLæ–‡ä»¶: {group_bddl_path}")
        
        # é‡æ–°åˆ›å»ºç¯å¢ƒä»¥ä½¿ç”¨æ–°çš„BDDLæ–‡ä»¶
        from libero.libero.envs import OffScreenRenderEnv
        env_args = {
            "bddl_file_name": str(group_bddl_path),
            "camera_heights": 224,
            "camera_widths": 224,
            "has_renderer": False,
            "has_offscreen_renderer": True,
            "use_camera_obs": True,
            "camera_names": ["frontview", "robot0_eye_in_hand"],
            "control_freq": 20,
        }
        env = OffScreenRenderEnv(**env_args)
        env.seed(config['execution']['seed_start'])
        print(f"   âœ… å·²åˆ‡æ¢åˆ°æ–°BDDLåœºæ™¯")
    
    print(f"{'='*60}\n")
    
    # âœ… åœ¨æ¯ä¸ªç»„å¼€å§‹å‰ï¼Œå…ˆåšä¸€æ¬¡å®Œæ•´é‡ç½®ï¼ˆæ¸…é™¤ä¹‹å‰ç»„çš„å½±å“ï¼‰
    print("ğŸ”„ é‡ç½®ç¯å¢ƒçŠ¶æ€...")
    env.reset()
    env.sim.data.qvel[:] = 0
    env.sim.forward()
    for _ in range(10):
        env.sim.step()
    print("âœ… ç¯å¢ƒçŠ¶æ€å·²æ¸…ç†\n")
    
    group_dir = output_dir / group_name
    group_dir.mkdir(parents=True, exist_ok=True)
    
    episodes_per_group = config['execution']['episodes_per_group']
    max_steps = config['execution']['max_steps_per_episode']
    
    results = []
    
    # âœ… åŠ è½½ä»»åŠ¡åˆå§‹çŠ¶æ€ï¼ˆä¿®å¤ PyTorch 2.6 å…¼å®¹æ€§ï¼‰
    init_states = None
    # åªæœ‰ä½¿ç”¨æ ‡å‡†LIBEROä»»åŠ¡æ—¶æ‰åŠ è½½åˆå§‹çŠ¶æ€
    if task_suite is not None:
        # ä¸´æ—¶ç¦ç”¨åˆå§‹çŠ¶æ€åŠ è½½ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…é—®é¢˜
        print(f"  â„¹ï¸  ä½¿ç”¨é»˜è®¤éšæœºåˆå§‹åŒ–ï¼ˆè·³è¿‡é¢„ä¿å­˜çŠ¶æ€ï¼‰")
    else:
        print(f"  â„¹ï¸  è‡ªå®šä¹‰BDDLåœºæ™¯ï¼Œä½¿ç”¨é»˜è®¤éšæœºåˆå§‹åŒ–")
    # try:
    #     import torch
    #     from libero.libero import get_libero_path
    #     init_states_path = Path(get_libero_path("init_states")) / task_suite.tasks[task_id].problem_folder / task_suite.tasks[task_id].init_states_file
    #     init_states = torch.load(init_states_path, weights_only=False)
    # except Exception as e:
    #     print(f"  âš ï¸  è­¦å‘Šï¼šæ— æ³•åŠ è½½åˆå§‹çŠ¶æ€: {e}")
    #     print(f"  âš ï¸  å°†ä½¿ç”¨é»˜è®¤éšæœºåˆå§‹åŒ–")
    
    for episode_idx in range(episodes_per_group):
        print(f"\nğŸ“ Episode {episode_idx + 1}/{episodes_per_group}")
        
        # åˆ›å»ºepisodeç›®å½•
        episode_dir = group_dir / f"episode_{episode_idx}"
        episode_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºåˆ†è§†è§’çš„imagesç›®å½•
        frontview_dir = episode_dir / "images" / "frontview"
        wrist_dir = episode_dir / "images" / "wrist"
        frontview_dir.mkdir(parents=True, exist_ok=True)
        wrist_dir.mkdir(parents=True, exist_ok=True)
        
        # âœ… å®Œå…¨é‡ç½®ç¯å¢ƒï¼šå…ˆresetï¼Œå†åŠ è½½åˆå§‹çŠ¶æ€
        obs = env.reset()
        if init_states is not None and len(init_states) > 0:
            obs = env.set_init_state(init_states[episode_idx % len(init_states)])
            print(f"  âœ“ åŠ è½½åˆå§‹çŠ¶æ€ (state {episode_idx % len(init_states)})")
        
        # âœ… ç¡®ä¿ç‰©ç†çŠ¶æ€ç¨³å®šï¼ˆæ¸…é›¶æ‰€æœ‰é€Ÿåº¦ï¼‰
        env.sim.data.qvel[:] = 0
        env.sim.forward()
        for _ in range(5):
            env.sim.step()
        
        # BDDLä¸­å·²å®šä¹‰å †å åœºæ™¯
        # æ‰€æœ‰é…ç½®éƒ½ä½¿ç”¨ use_bddl_stacking: trueï¼Œä¸éœ€è¦åŠ¨æ€ä¿®æ”¹
        if group_config.get('use_bddl_stacking', False):
            print(f"  â„¹ï¸  ä½¿ç”¨BDDLå®šä¹‰çš„å †å åœºæ™¯")
        
        # è¿è¡Œæ¨ç†
        instruction = group_config['instruction']
        episode_success = False
        step_count = 0
        inference_count = 0
        
        print(f"  æŒ‡ä»¤: {instruction}")
        
        # é‡ç½®æ¨¡å‹çŠ¶æ€
        model.reset()
        
        # åŠ¨ä½œåºåˆ—ç¼“å­˜æœºåˆ¶
        action_cache = []
        action_cache_step = 0
        
        for step in range(max_steps):
            # æå–çŠ¶æ€å’Œå›¾åƒ
            robot_state = extract_robot_state_from_obs(obs)
            base_image = process_camera_image(obs, "frontview_image")
            wrist_image = process_camera_image(obs, "robot0_eye_in_hand_image")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°çš„æ¨ç†
            if len(action_cache) == 0 or action_cache_step >= len(action_cache):
                # éœ€è¦æ–°æ¨ç†
                inference_count += 1
                
                # æ„å»ºæ¨¡å‹è¾“å…¥
                model_input = {
                    "observation/state": robot_state,
                    "observation/image": base_image,
                    "observation/wrist_image": wrist_image,
                    "prompt": instruction
                }
                
                # Pi0.5æ¨ç†
                with torch.no_grad():
                    result = model.infer(model_input)
                    action_sequence = result["actions"]  # å®Œæ•´åŠ¨ä½œåºåˆ—
                
                # æ›´æ–°ç¼“å­˜
                action_cache = action_sequence
                action_cache_step = 0
                
                if step % 50 == 0 or inference_count <= 3:
                    print(f"  [æ¨ç†{inference_count}] æ­¥éª¤{step+1}: ç”Ÿæˆ{len(action_cache)}æ­¥åŠ¨ä½œåºåˆ—")
            
            # ä»ç¼“å­˜ä¸­è·å–åŠ¨ä½œ
            action = action_cache[action_cache_step]
            action_cache_step += 1
            
            # è½¬æ¢ä¸ºnumpy
            if isinstance(action, torch.Tensor):
                action = action.cpu().numpy().squeeze()
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, done, info = env.step(action)
            step_count += 1
            
            # æ¯æ­¥éƒ½ä¿å­˜å›¾åƒ
            try:
                # è½¬æ¢é¢œè‰²é€šé“ RGB -> BGR (OpenCVæ ¼å¼)
                front_bgr = cv2.cvtColor(base_image, cv2.COLOR_RGB2BGR)
                wrist_bgr = cv2.cvtColor(wrist_image, cv2.COLOR_RGB2BGR)
                
                # ä¿å­˜å›¾åƒæ–‡ä»¶
                frontview_filename = frontview_dir / f"step_{step_count:05d}.png"
                wrist_filename = wrist_dir / f"step_{step_count:05d}.png"
                
                cv2.imwrite(str(frontview_filename), front_bgr)
                cv2.imwrite(str(wrist_filename), wrist_bgr)
            except Exception as e:
                print(f"    âš ï¸  å›¾åƒä¿å­˜é”™è¯¯: {e}")
            
            if step % 50 == 0:
                print(f"    Step {step_count}")
            
            if done:
                # âœ… ä¿®æ”¹åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœæå‰é€€å‡ºï¼ˆdone=Trueï¼‰ï¼Œåˆ™è®¤ä¸ºæˆåŠŸ
                episode_success = True
                print(f"    âœ“ ä»»åŠ¡æå‰å®Œæˆäºæ­¥éª¤ {step_count}/{max_steps}")
                break
        
        # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä»æœªå®Œæˆï¼Œåˆ™åˆ¤å®šä¸ºå¤±è´¥
        if step_count >= max_steps and not episode_success:
            print(f"    âœ— è¾¾åˆ°æœ€å¤§æ­¥æ•° {max_steps}ï¼Œä»»åŠ¡æœªå®Œæˆ")
        
        # ä¿å­˜ç»“æœ
        episode_result = {
            'episode': episode_idx,
            'success': episode_success,
            'steps': step_count,
            'inference_count': inference_count,
            'instruction': instruction,
            'obstruction': group_config['use_obstruction']
        }
        
        results.append(episode_result)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(episode_dir / "result.json", 'w') as f:
            json.dump(episode_result, f, indent=2)
        
        status = "âœ… æˆåŠŸ" if episode_success else "âŒ å¤±è´¥"
        print(f"  {status} (æ­¥æ•°: {step_count}, æ¨ç†: {inference_count}æ¬¡)")
    
    # è®¡ç®—ç»Ÿè®¡
    success_count = sum(1 for r in results if r['success'])
    success_rate = success_count / len(results) if results else 0
    
    summary = {
        'group_name': group_name,
        'description': group_config['description'],
        'instruction': group_config['instruction'],
        'use_obstruction': group_config['use_obstruction'],
        'episodes': len(results),
        'success_count': success_count,
        'success_rate': success_rate,
        'results': results
    }
    
    # ä¿å­˜ç»„ç»Ÿè®¡
    with open(group_dir / "summary.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nğŸ“Š {group_name} ç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {success_count}/{len(results)} ({success_rate*100:.1f}%)")
    
    return env, summary


def run_experiment(config_path: str):
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¯åŠ¨å®éªŒ: {config['experiment']['name']}")
    print(f"   æè¿°: {config['experiment']['description']}")
    print(f"{'='*60}\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„results_dirï¼Œä¸å†æ·»åŠ å®éªŒåï¼‰
    output_dir = Path(config['output']['results_dir'])
    
    # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œæ¸…ç©ºå®ƒ
    if output_dir.exists():
        import shutil
        shutil.rmtree(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜é…ç½®
    with open(output_dir / "config.yaml", 'w') as f:
        yaml.dump(config, f)
    
    print(f"ğŸ“ ç»“æœç›®å½•: {output_dir}\n")
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    print("ğŸ”§ åˆå§‹åŒ–LIBEROç¯å¢ƒ...")
    from libero.libero import benchmark, get_libero_path
    from libero.libero.envs import OffScreenRenderEnv
    
    task_name = config['task']['task_name']
    suite = config['task']['suite']
    
    # âœ… æ”¯æŒè‡ªå®šä¹‰BDDLæ–‡ä»¶æˆ–custom suite
    if 'bddl_file' in config['task'] or suite == 'custom':
        # ä½¿ç”¨è‡ªå®šä¹‰BDDLæ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰æˆ–è€…ç”±å„ç»„è‡ªå·±æŒ‡å®š
        if 'bddl_file' in config['task']:
            custom_bddl_path = config['task']['bddl_file']
            if not custom_bddl_path.startswith('/'):
                custom_bddl_path = SCRIPT_DIR.parent / custom_bddl_path
                if not custom_bddl_path.exists():
                    custom_bddl_path = Path(custom_bddl_path)
            else:
                custom_bddl_path = Path(custom_bddl_path)
            task_bddl_file = custom_bddl_path
            print(f"   ä»»åŠ¡: {task_name}")
            print(f"   ä½¿ç”¨è‡ªå®šä¹‰BDDL: {task_bddl_file}")
        else:
            # custom suiteï¼Œç”±å„ç»„è‡ªå·±æŒ‡å®šBDDL
            task_bddl_file = None
            print(f"   ä»»åŠ¡: {task_name}")
            print(f"   ä½¿ç”¨custom suiteï¼Œå„ç»„å°†æŒ‡å®šå„è‡ªçš„BDDLæ–‡ä»¶")
        
        task_suite = None
        task_id = 0
    else:
        # ä½¿ç”¨æ ‡å‡†LIBEROä»»åŠ¡
        task_id = find_task_id_by_name(task_name, suite)
        print(f"   ä»»åŠ¡: {task_name}")
        print(f"   Task ID: {task_id}")
        
        # åˆ›å»ºç¯å¢ƒ
        benchmark_dict = benchmark.get_benchmark_dict()
        task_suite = benchmark_dict[suite]()
        task = task_suite.get_task(task_id)
        
        task_bddl_file = Path(get_libero_path("bddl_files")) / task.problem_folder / task.bddl_file
    
    # åˆ›å»ºåˆå§‹ç¯å¢ƒï¼ˆå¦‚æœæœ‰é»˜è®¤BDDLï¼‰
    env = None
    if task_bddl_file is not None:
        env_args = {
            "bddl_file_name": str(task_bddl_file),
            "camera_heights": 224,
            "camera_widths": 224,
            "has_renderer": False,
            "has_offscreen_renderer": True,
            "use_camera_obs": True,
            "camera_names": ["frontview", "robot0_eye_in_hand"],  # âœ… ä½¿ç”¨frontview
            "control_freq": 20,
        }
        
        env = OffScreenRenderEnv(**env_args)
        env.seed(config['execution']['seed_start'])
        
        print("âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ\n")
    else:
        print("   ç¯å¢ƒå°†åœ¨å„ç»„ä¸­æ ¹æ®BDDLæ–‡ä»¶åˆ›å»º\n")
    
    # åŠ è½½Pi0.5æ¨¡å‹
    print("ğŸ¤– åŠ è½½Pi0.5æ¨¡å‹...")
    checkpoint_dir = config['execution']['checkpoint_dir']
    model, model_config = load_pi05_model(checkpoint_dir)
    
    if model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å®éªŒ")
        if env is not None:
            env.close()
        return
    
    # è¿è¡Œæ‰€æœ‰å®éªŒç»„
    all_summaries = []
    
    for group_idx, group_config in enumerate(config['groups'], 1):
        group_name = f"group{group_idx}_{group_config['name']}"
        
        try:
            # âœ… è‡ªå®šä¹‰BDDLæ—¶task_suiteå¯èƒ½ä¸ºNoneï¼Œä¸ä½¿ç”¨åˆå§‹çŠ¶æ€
            env, summary = run_group_with_cache(
                env, config, group_config, group_name,
                output_dir, model, model_config, task_suite, task_id
            )
            all_summaries.append(summary)
        except Exception as e:
            print(f"âŒ å®éªŒç»„ {group_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ç”Ÿæˆæ€»æŠ¥å‘Š
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report = {
        'experiment': config['experiment']['name'],
        'timestamp': timestamp,
        'task': task_name,
        'groups': all_summaries
    }
    
    with open(output_dir / "report.json", 'w') as f:
        json.dump(report, f, indent=2)
    
    # æ‰“å°æ€»ç»“
    print(f"\n{'='*60}")
    print(f"âœ… å®éªŒå®Œæˆ!")
    print(f"{'='*60}")
    print(f"\nğŸ“Š æ€»ç»“:")
    for summary in all_summaries:
        print(f"   {summary['group_name']}: {summary['success_rate']*100:.1f}% "
              f"({summary['success_count']}/{summary['episodes']})")
    
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"\nè¿è¡Œåˆ†æè„šæœ¬:")
    print(f"   python experiments/obstruction/scripts/analyze_results.py \\")
    print(f"       --results_dir {output_dir}")
    
    if env is not None:
        env.close()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True,
                       help="å®éªŒé…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    run_experiment(args.config)
